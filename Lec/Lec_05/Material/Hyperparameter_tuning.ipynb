{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12958428-4d43-4cb4-85e1-3655872fdecf",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "## Part 1: Manual Hyperparameter Tuning\n",
    "### Objective\n",
    "Manually tune hyperparameters of a neural network and observe the impact on model performance.\n",
    "\n",
    "### Setup\n",
    "Start with the necessary imports and dataset preparation. We'll use the MNIST dataset for this exercise, as it's complex enough to demonstrate the effects of hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660f35c7-8216-4090-8254-232038418180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "X_train, X_test = X_train.reshape(-1, 784) / 255.0, X_test.reshape(-1, 784) / 255.0\n",
    "y_train, y_test = keras.utils.to_categorical(y_train, 10), keras.utils.to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4df2a6d-419d-4f89-8c8d-bbf3ee27617b",
   "metadata": {},
   "source": [
    "## Task: Manual Tuning of Hyperparameters\n",
    "1. Build a Base Model: Create a simple neural network as a starting point.\n",
    "2. Manual Tuning: Experiment by manually changing hyperparameters like learning rate, number of layers/neurons, and activation functions.\n",
    "3. Training and Evaluation: Train the model with different hyperparameter settings and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84ec10a6-9de9-4bee-9212-012d04f1dd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 1.3902 - accuracy: 0.4549 - val_loss: 0.7626 - val_accuracy: 0.7418\n",
      "Epoch 2/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7682 - accuracy: 0.7594 - val_loss: 0.5915 - val_accuracy: 0.8440\n",
      "Epoch 3/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.7551 - accuracy: 0.7867 - val_loss: 0.6478 - val_accuracy: 0.8347\n",
      "Epoch 4/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.6252 - accuracy: 0.8382 - val_loss: 0.5115 - val_accuracy: 0.8865\n",
      "Epoch 5/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7330 - accuracy: 0.7613 - val_loss: 0.7054 - val_accuracy: 0.7443\n",
      "Epoch 6/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5731 - accuracy: 0.8281 - val_loss: 0.4825 - val_accuracy: 0.8795\n",
      "Epoch 7/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5334 - accuracy: 0.8648 - val_loss: 0.5444 - val_accuracy: 0.8602\n",
      "Epoch 8/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5082 - accuracy: 0.8728 - val_loss: 0.5602 - val_accuracy: 0.8650\n",
      "Epoch 9/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5895 - accuracy: 0.8525 - val_loss: 0.5106 - val_accuracy: 0.8852\n",
      "Epoch 10/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4630 - accuracy: 0.8932 - val_loss: 0.5237 - val_accuracy: 0.8810\n",
      "Epoch 11/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.6195 - accuracy: 0.8319 - val_loss: 0.9611 - val_accuracy: 0.6874\n",
      "Epoch 12/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7839 - accuracy: 0.7627 - val_loss: 0.6443 - val_accuracy: 0.8211\n",
      "Epoch 13/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.8370 - accuracy: 0.7155 - val_loss: 0.8398 - val_accuracy: 0.7040\n",
      "Epoch 14/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7591 - accuracy: 0.7563 - val_loss: 0.6000 - val_accuracy: 0.8573\n",
      "Epoch 15/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5618 - accuracy: 0.8580 - val_loss: 0.4853 - val_accuracy: 0.8872\n",
      "Epoch 16/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.4666 - accuracy: 0.8918 - val_loss: 0.7906 - val_accuracy: 0.7502\n",
      "Epoch 17/32\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4154 - accuracy: 0.9070 - val_loss: 0.4129 - val_accuracy: 0.9058\n",
      "Epoch 18/32\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4190 - accuracy: 0.9065 - val_loss: 0.3913 - val_accuracy: 0.9183\n",
      "Epoch 19/32\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4334 - accuracy: 0.9023 - val_loss: 0.4179 - val_accuracy: 0.9084\n",
      "Epoch 20/32\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4009 - accuracy: 0.9127 - val_loss: 0.4064 - val_accuracy: 0.9140\n",
      "Epoch 21/32\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4027 - accuracy: 0.9109 - val_loss: 0.4366 - val_accuracy: 0.9006\n",
      "Epoch 22/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3832 - accuracy: 0.9177 - val_loss: 0.4404 - val_accuracy: 0.9019\n",
      "Epoch 23/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.4658 - accuracy: 0.8864 - val_loss: 0.4446 - val_accuracy: 0.8997\n",
      "Epoch 24/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5140 - accuracy: 0.8728 - val_loss: 0.4779 - val_accuracy: 0.8900\n",
      "Epoch 25/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5119 - accuracy: 0.8712 - val_loss: 0.5017 - val_accuracy: 0.8748\n",
      "Epoch 26/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.4356 - accuracy: 0.8974 - val_loss: 0.4032 - val_accuracy: 0.9136\n",
      "Epoch 27/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.4093 - accuracy: 0.9033 - val_loss: 0.4183 - val_accuracy: 0.9059\n",
      "Epoch 28/32\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3945 - accuracy: 0.9095 - val_loss: 0.3781 - val_accuracy: 0.9197\n",
      "Epoch 29/32\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4687 - accuracy: 0.8830 - val_loss: 0.4864 - val_accuracy: 0.8857\n",
      "Epoch 30/32\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5205 - accuracy: 0.8650 - val_loss: 0.5341 - val_accuracy: 0.8678\n",
      "Epoch 31/32\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5407 - accuracy: 0.8638 - val_loss: 0.5050 - val_accuracy: 0.8727\n",
      "Epoch 32/32\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.6388 - accuracy: 0.8256 - val_loss: 0.6892 - val_accuracy: 0.7942\n",
      "Epoch 1/32\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 2.3015 - accuracy: 0.1130 - val_loss: 2.3025 - val_accuracy: 0.1060\n",
      "Epoch 2/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3024 - val_accuracy: 0.1060\n",
      "Epoch 3/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3013 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 4/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 5/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3025 - val_accuracy: 0.1060\n",
      "Epoch 6/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 7/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 8/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 9/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 10/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 11/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 12/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 13/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 14/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 15/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 16/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3025 - val_accuracy: 0.1060\n",
      "Epoch 17/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 18/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 19/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 20/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 21/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 22/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 23/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 24/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 25/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 26/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 27/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 28/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 29/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 30/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 31/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 32/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 1/32\n",
      "1500/1500 [==============================] - 28s 17ms/step - loss: 2.3016 - accuracy: 0.1131 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 2/32\n",
      "1500/1500 [==============================] - 27s 18ms/step - loss: 2.3013 - accuracy: 0.1140 - val_loss: 2.3026 - val_accuracy: 0.1060\n",
      "Epoch 3/32\n",
      "1500/1500 [==============================] - 26s 18ms/step - loss: 2.3013 - accuracy: 0.1140 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 4/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 5/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 6/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 7/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 8/32\n",
      "1500/1500 [==============================] - 25s 17ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 9/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 10/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 11/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 12/32\n",
      "1500/1500 [==============================] - 25s 17ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 13/32\n",
      "1500/1500 [==============================] - 25s 17ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 14/32\n",
      "1500/1500 [==============================] - 25s 17ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 15/32\n",
      "1500/1500 [==============================] - 25s 17ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 16/32\n",
      "1500/1500 [==============================] - 25s 17ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 17/32\n",
      "1500/1500 [==============================] - 25s 17ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 18/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 19/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 20/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 21/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 22/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 23/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 24/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 25/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 26/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 27/32\n",
      "1500/1500 [==============================] - 25s 17ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 28/32\n",
      "1500/1500 [==============================] - 25s 17ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 29/32\n",
      "1500/1500 [==============================] - 25s 17ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 30/32\n",
      "1500/1500 [==============================] - 25s 17ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 31/32\n",
      "1500/1500 [==============================] - 25s 17ms/step - loss: 2.3012 - accuracy: 0.1140 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 32/32\n",
      "1500/1500 [==============================] - 25s 17ms/step - loss: 2.3011 - accuracy: 0.1140 - val_loss: 2.3024 - val_accuracy: 0.1060\n",
      "Epoch 1/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 2.3027 - accuracy: 0.1110 - val_loss: 2.3033 - val_accuracy: 0.1060\n",
      "Epoch 2/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3024 - accuracy: 0.1119 - val_loss: 2.3033 - val_accuracy: 0.1060\n",
      "Epoch 3/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3023 - accuracy: 0.1114 - val_loss: 2.3024 - val_accuracy: 0.1060\n",
      "Epoch 4/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3022 - accuracy: 0.1107 - val_loss: 2.3035 - val_accuracy: 0.1060\n",
      "Epoch 5/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3024 - accuracy: 0.1116 - val_loss: 2.3025 - val_accuracy: 0.1060\n",
      "Epoch 6/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3025 - accuracy: 0.1115 - val_loss: 2.3030 - val_accuracy: 0.1060\n",
      "Epoch 7/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3023 - accuracy: 0.1118 - val_loss: 2.3030 - val_accuracy: 0.1060\n",
      "Epoch 8/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3021 - accuracy: 0.1096 - val_loss: 2.3032 - val_accuracy: 0.1081\n",
      "Epoch 9/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3022 - accuracy: 0.1105 - val_loss: 2.3028 - val_accuracy: 0.1060\n",
      "Epoch 10/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3023 - accuracy: 0.1111 - val_loss: 2.3030 - val_accuracy: 0.1060\n",
      "Epoch 11/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3023 - accuracy: 0.1111 - val_loss: 2.3034 - val_accuracy: 0.1060\n",
      "Epoch 12/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3025 - accuracy: 0.1121 - val_loss: 2.3030 - val_accuracy: 0.1060\n",
      "Epoch 13/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3025 - accuracy: 0.1117 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 14/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3025 - accuracy: 0.1115 - val_loss: 2.3030 - val_accuracy: 0.1060\n",
      "Epoch 15/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 2.3024 - accuracy: 0.1119 - val_loss: 2.3031 - val_accuracy: 0.1060\n",
      "Epoch 16/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 2.3022 - accuracy: 0.1121 - val_loss: 2.3039 - val_accuracy: 0.1060\n",
      "Epoch 17/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 2.3025 - accuracy: 0.1105 - val_loss: 2.3030 - val_accuracy: 0.1060\n",
      "Epoch 18/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 2.3022 - accuracy: 0.1111 - val_loss: 2.3040 - val_accuracy: 0.1035\n",
      "Epoch 19/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 2.3025 - accuracy: 0.1110 - val_loss: 2.3029 - val_accuracy: 0.0956\n",
      "Epoch 20/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 2.3023 - accuracy: 0.1105 - val_loss: 2.3026 - val_accuracy: 0.1060\n",
      "Epoch 21/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 2.3024 - accuracy: 0.1112 - val_loss: 2.3037 - val_accuracy: 0.1060\n",
      "Epoch 22/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3024 - accuracy: 0.1124 - val_loss: 2.3028 - val_accuracy: 0.1060\n",
      "Epoch 23/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3022 - accuracy: 0.1116 - val_loss: 2.3030 - val_accuracy: 0.1060\n",
      "Epoch 24/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 2.3021 - accuracy: 0.1125 - val_loss: 2.3055 - val_accuracy: 0.1060\n",
      "Epoch 25/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 2.3022 - accuracy: 0.1113 - val_loss: 2.3053 - val_accuracy: 0.1060\n",
      "Epoch 26/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3025 - accuracy: 0.1123 - val_loss: 2.3036 - val_accuracy: 0.1035\n",
      "Epoch 27/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 2.3024 - accuracy: 0.1108 - val_loss: 2.3040 - val_accuracy: 0.1060\n",
      "Epoch 28/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 2.3022 - accuracy: 0.1117 - val_loss: 2.3039 - val_accuracy: 0.1060\n",
      "Epoch 29/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 2.3026 - accuracy: 0.1121 - val_loss: 2.3024 - val_accuracy: 0.1060\n",
      "Epoch 30/32\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 2.3022 - accuracy: 0.1107 - val_loss: 2.3041 - val_accuracy: 0.0997\n",
      "Epoch 31/32\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 2.3022 - accuracy: 0.1114 - val_loss: 2.3032 - val_accuracy: 0.1060\n",
      "Epoch 32/32\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 2.3024 - accuracy: 0.1103 - val_loss: 2.3029 - val_accuracy: 0.1060\n",
      "Epoch 1/32\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 2.3025 - accuracy: 0.1116 - val_loss: 2.3033 - val_accuracy: 0.1060\n",
      "Epoch 2/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3024 - accuracy: 0.1107 - val_loss: 2.3036 - val_accuracy: 0.1060\n",
      "Epoch 3/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3024 - accuracy: 0.1123 - val_loss: 2.3038 - val_accuracy: 0.0997\n",
      "Epoch 4/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3024 - accuracy: 0.1111 - val_loss: 2.3027 - val_accuracy: 0.1035\n",
      "Epoch 5/32\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.3023 - accuracy: 0.1110 - val_loss: 2.3029 - val_accuracy: 0.1060\n",
      "Epoch 6/32\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.3024 - accuracy: 0.1118 - val_loss: 2.3032 - val_accuracy: 0.1060\n",
      "Epoch 7/32\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 2.3022 - accuracy: 0.1122 - val_loss: 2.3026 - val_accuracy: 0.1060\n",
      "Epoch 8/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3022 - accuracy: 0.1120 - val_loss: 2.3033 - val_accuracy: 0.1060\n",
      "Epoch 9/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3026 - accuracy: 0.1112 - val_loss: 2.3020 - val_accuracy: 0.1081\n",
      "Epoch 10/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3024 - accuracy: 0.1111 - val_loss: 2.3027 - val_accuracy: 0.0998\n",
      "Epoch 11/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3023 - accuracy: 0.1114 - val_loss: 2.3041 - val_accuracy: 0.1060\n",
      "Epoch 12/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3023 - accuracy: 0.1109 - val_loss: 2.3028 - val_accuracy: 0.0975\n",
      "Epoch 13/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3025 - accuracy: 0.1106 - val_loss: 2.3026 - val_accuracy: 0.1060\n",
      "Epoch 14/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3023 - accuracy: 0.1130 - val_loss: 2.3041 - val_accuracy: 0.1060\n",
      "Epoch 15/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3024 - accuracy: 0.1130 - val_loss: 2.3030 - val_accuracy: 0.1060\n",
      "Epoch 16/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3022 - accuracy: 0.1112 - val_loss: 2.3024 - val_accuracy: 0.1060\n",
      "Epoch 17/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3021 - accuracy: 0.1104 - val_loss: 2.3031 - val_accuracy: 0.1060\n",
      "Epoch 18/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3024 - accuracy: 0.1114 - val_loss: 2.3038 - val_accuracy: 0.1060\n",
      "Epoch 19/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3024 - accuracy: 0.1124 - val_loss: 2.3030 - val_accuracy: 0.1081\n",
      "Epoch 20/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3024 - accuracy: 0.1114 - val_loss: 2.3027 - val_accuracy: 0.1060\n",
      "Epoch 21/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3024 - accuracy: 0.1103 - val_loss: 2.3027 - val_accuracy: 0.1060\n",
      "Epoch 22/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3023 - accuracy: 0.1125 - val_loss: 2.3026 - val_accuracy: 0.0998\n",
      "Epoch 23/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3024 - accuracy: 0.1114 - val_loss: 2.3035 - val_accuracy: 0.1060\n",
      "Epoch 24/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3023 - accuracy: 0.1124 - val_loss: 2.3033 - val_accuracy: 0.1060\n",
      "Epoch 25/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3025 - accuracy: 0.1122 - val_loss: 2.3032 - val_accuracy: 0.1060\n",
      "Epoch 26/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3025 - accuracy: 0.1111 - val_loss: 2.3033 - val_accuracy: 0.1060\n",
      "Epoch 27/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3023 - accuracy: 0.1116 - val_loss: 2.3026 - val_accuracy: 0.1060\n",
      "Epoch 28/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3025 - accuracy: 0.1111 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 29/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3024 - accuracy: 0.1118 - val_loss: 2.3029 - val_accuracy: 0.1060\n",
      "Epoch 30/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3023 - accuracy: 0.1120 - val_loss: 2.3023 - val_accuracy: 0.1081\n",
      "Epoch 31/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3024 - accuracy: 0.1121 - val_loss: 2.3038 - val_accuracy: 0.1060\n",
      "Epoch 32/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3024 - accuracy: 0.1107 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 1/32\n",
      "1500/1500 [==============================] - 27s 17ms/step - loss: 2.3027 - accuracy: 0.1106 - val_loss: 2.3028 - val_accuracy: 0.1081\n",
      "Epoch 2/32\n",
      "1500/1500 [==============================] - 25s 17ms/step - loss: 2.3024 - accuracy: 0.1109 - val_loss: 2.3020 - val_accuracy: 0.1060\n",
      "Epoch 3/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3022 - accuracy: 0.1113 - val_loss: 2.3038 - val_accuracy: 0.0995\n",
      "Epoch 4/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3023 - accuracy: 0.1103 - val_loss: 2.3027 - val_accuracy: 0.1060\n",
      "Epoch 5/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3023 - accuracy: 0.1114 - val_loss: 2.3025 - val_accuracy: 0.1060\n",
      "Epoch 6/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3022 - accuracy: 0.1101 - val_loss: 2.3039 - val_accuracy: 0.1060\n",
      "Epoch 7/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3024 - accuracy: 0.1115 - val_loss: 2.3035 - val_accuracy: 0.1035\n",
      "Epoch 8/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3021 - accuracy: 0.1112 - val_loss: 2.3030 - val_accuracy: 0.0956\n",
      "Epoch 9/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3025 - accuracy: 0.1112 - val_loss: 2.3047 - val_accuracy: 0.1060\n",
      "Epoch 10/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3023 - accuracy: 0.1126 - val_loss: 2.3030 - val_accuracy: 0.1060\n",
      "Epoch 11/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3026 - accuracy: 0.1099 - val_loss: 2.3035 - val_accuracy: 0.1060\n",
      "Epoch 12/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3023 - accuracy: 0.1106 - val_loss: 2.3029 - val_accuracy: 0.1060\n",
      "Epoch 13/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3025 - accuracy: 0.1121 - val_loss: 2.3048 - val_accuracy: 0.1060\n",
      "Epoch 14/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3023 - accuracy: 0.1124 - val_loss: 2.3037 - val_accuracy: 0.0956\n",
      "Epoch 15/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3023 - accuracy: 0.1100 - val_loss: 2.3031 - val_accuracy: 0.1060\n",
      "Epoch 16/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3023 - accuracy: 0.1113 - val_loss: 2.3030 - val_accuracy: 0.1060\n",
      "Epoch 17/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3024 - accuracy: 0.1126 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "Epoch 18/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3023 - accuracy: 0.1119 - val_loss: 2.3033 - val_accuracy: 0.1060\n",
      "Epoch 19/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3023 - accuracy: 0.1107 - val_loss: 2.3032 - val_accuracy: 0.1060\n",
      "Epoch 20/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3024 - accuracy: 0.1110 - val_loss: 2.3041 - val_accuracy: 0.1060\n",
      "Epoch 21/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3023 - accuracy: 0.1116 - val_loss: 2.3054 - val_accuracy: 0.1060\n",
      "Epoch 22/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3023 - accuracy: 0.1100 - val_loss: 2.3024 - val_accuracy: 0.1060\n",
      "Epoch 23/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3024 - accuracy: 0.1118 - val_loss: 2.3033 - val_accuracy: 0.1060\n",
      "Epoch 24/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3022 - accuracy: 0.1099 - val_loss: 2.3026 - val_accuracy: 0.1060\n",
      "Epoch 25/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3024 - accuracy: 0.1106 - val_loss: 2.3028 - val_accuracy: 0.1060\n",
      "Epoch 26/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3024 - accuracy: 0.1124 - val_loss: 2.3030 - val_accuracy: 0.1060\n",
      "Epoch 27/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3023 - accuracy: 0.1131 - val_loss: 2.3022 - val_accuracy: 0.1060\n",
      "Epoch 28/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3025 - accuracy: 0.1105 - val_loss: 2.3036 - val_accuracy: 0.1060\n",
      "Epoch 29/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3024 - accuracy: 0.1116 - val_loss: 2.3038 - val_accuracy: 0.1060\n",
      "Epoch 30/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3023 - accuracy: 0.1131 - val_loss: 2.3038 - val_accuracy: 0.1060\n",
      "Epoch 31/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3025 - accuracy: 0.1104 - val_loss: 2.3047 - val_accuracy: 0.1060\n",
      "Epoch 32/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 2.3022 - accuracy: 0.1116 - val_loss: 2.3038 - val_accuracy: 0.0956\n",
      "Epoch 1/32\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 2.3305 - accuracy: 0.1031 - val_loss: 2.3059 - val_accuracy: 0.0956\n",
      "Epoch 2/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3136 - accuracy: 0.1050 - val_loss: 2.3081 - val_accuracy: 0.0998\n",
      "Epoch 3/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3142 - accuracy: 0.1032 - val_loss: 2.3208 - val_accuracy: 0.1081\n",
      "Epoch 4/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3136 - accuracy: 0.1039 - val_loss: 2.3172 - val_accuracy: 0.1060\n",
      "Epoch 5/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3145 - accuracy: 0.1045 - val_loss: 2.3106 - val_accuracy: 0.1060\n",
      "Epoch 6/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3140 - accuracy: 0.1033 - val_loss: 2.3146 - val_accuracy: 0.0956\n",
      "Epoch 7/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3144 - accuracy: 0.1022 - val_loss: 2.3112 - val_accuracy: 0.0989\n",
      "Epoch 8/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3140 - accuracy: 0.1045 - val_loss: 2.3150 - val_accuracy: 0.0998\n",
      "Epoch 9/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3136 - accuracy: 0.1020 - val_loss: 2.3096 - val_accuracy: 0.0998\n",
      "Epoch 10/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3138 - accuracy: 0.1040 - val_loss: 2.3165 - val_accuracy: 0.1081\n",
      "Epoch 11/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3134 - accuracy: 0.1036 - val_loss: 2.3146 - val_accuracy: 0.0975\n",
      "Epoch 12/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3142 - accuracy: 0.1029 - val_loss: 2.3157 - val_accuracy: 0.0989\n",
      "Epoch 13/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3154 - accuracy: 0.1039 - val_loss: 2.3122 - val_accuracy: 0.1060\n",
      "Epoch 14/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3142 - accuracy: 0.1019 - val_loss: 2.3121 - val_accuracy: 0.1060\n",
      "Epoch 15/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3134 - accuracy: 0.1037 - val_loss: 2.3240 - val_accuracy: 0.1060\n",
      "Epoch 16/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3131 - accuracy: 0.1035 - val_loss: 2.3118 - val_accuracy: 0.1060\n",
      "Epoch 17/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3140 - accuracy: 0.1027 - val_loss: 2.3094 - val_accuracy: 0.1060\n",
      "Epoch 18/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3147 - accuracy: 0.1058 - val_loss: 2.3159 - val_accuracy: 0.0989\n",
      "Epoch 19/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3138 - accuracy: 0.1049 - val_loss: 2.3307 - val_accuracy: 0.0989\n",
      "Epoch 20/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3142 - accuracy: 0.1041 - val_loss: 2.3122 - val_accuracy: 0.1081\n",
      "Epoch 21/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3144 - accuracy: 0.1043 - val_loss: 2.3121 - val_accuracy: 0.1081\n",
      "Epoch 22/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3141 - accuracy: 0.1049 - val_loss: 2.3153 - val_accuracy: 0.0997\n",
      "Epoch 23/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3141 - accuracy: 0.1023 - val_loss: 2.3114 - val_accuracy: 0.1060\n",
      "Epoch 24/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3127 - accuracy: 0.1055 - val_loss: 2.3173 - val_accuracy: 0.0956\n",
      "Epoch 25/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3131 - accuracy: 0.1028 - val_loss: 2.3203 - val_accuracy: 0.1060\n",
      "Epoch 26/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3139 - accuracy: 0.1020 - val_loss: 2.3097 - val_accuracy: 0.1060\n",
      "Epoch 27/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3127 - accuracy: 0.1041 - val_loss: 2.3144 - val_accuracy: 0.1060\n",
      "Epoch 28/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3138 - accuracy: 0.1026 - val_loss: 2.3224 - val_accuracy: 0.0997\n",
      "Epoch 29/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3135 - accuracy: 0.1032 - val_loss: 2.3161 - val_accuracy: 0.1035\n",
      "Epoch 30/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3134 - accuracy: 0.1032 - val_loss: 2.3183 - val_accuracy: 0.1081\n",
      "Epoch 31/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3144 - accuracy: 0.1013 - val_loss: 2.3186 - val_accuracy: 0.0998\n",
      "Epoch 32/32\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 2.3140 - accuracy: 0.1050 - val_loss: 2.3107 - val_accuracy: 0.1060\n",
      "Epoch 1/32\n",
      "1500/1500 [==============================] - 9s 5ms/step - loss: 29.9255 - accuracy: 0.1027 - val_loss: 2.3110 - val_accuracy: 0.1060\n",
      "Epoch 2/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3134 - accuracy: 0.1026 - val_loss: 2.3095 - val_accuracy: 0.0997\n",
      "Epoch 3/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3144 - accuracy: 0.1052 - val_loss: 2.3149 - val_accuracy: 0.1081\n",
      "Epoch 4/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3146 - accuracy: 0.1037 - val_loss: 2.3051 - val_accuracy: 0.1035\n",
      "Epoch 5/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3139 - accuracy: 0.1026 - val_loss: 2.3171 - val_accuracy: 0.0975\n",
      "Epoch 6/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3139 - accuracy: 0.1049 - val_loss: 2.3143 - val_accuracy: 0.0997\n",
      "Epoch 7/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3138 - accuracy: 0.1037 - val_loss: 2.3093 - val_accuracy: 0.0995\n",
      "Epoch 8/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3140 - accuracy: 0.1055 - val_loss: 2.3198 - val_accuracy: 0.0975\n",
      "Epoch 9/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3139 - accuracy: 0.1047 - val_loss: 2.3185 - val_accuracy: 0.0995\n",
      "Epoch 10/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3140 - accuracy: 0.1036 - val_loss: 2.3125 - val_accuracy: 0.1081\n",
      "Epoch 11/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3140 - accuracy: 0.1044 - val_loss: 2.3074 - val_accuracy: 0.1035\n",
      "Epoch 12/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3146 - accuracy: 0.1011 - val_loss: 2.3121 - val_accuracy: 0.1081\n",
      "Epoch 13/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3123 - accuracy: 0.1061 - val_loss: 2.3067 - val_accuracy: 0.1060\n",
      "Epoch 14/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3133 - accuracy: 0.1050 - val_loss: 2.3043 - val_accuracy: 0.1035\n",
      "Epoch 15/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3135 - accuracy: 0.1052 - val_loss: 2.3116 - val_accuracy: 0.1060\n",
      "Epoch 16/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3141 - accuracy: 0.1030 - val_loss: 2.3105 - val_accuracy: 0.1060\n",
      "Epoch 17/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3134 - accuracy: 0.1047 - val_loss: 2.3075 - val_accuracy: 0.0998\n",
      "Epoch 18/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3145 - accuracy: 0.1020 - val_loss: 2.3060 - val_accuracy: 0.0998\n",
      "Epoch 19/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3142 - accuracy: 0.1025 - val_loss: 2.3177 - val_accuracy: 0.0995\n",
      "Epoch 20/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3141 - accuracy: 0.1057 - val_loss: 2.3221 - val_accuracy: 0.0914\n",
      "Epoch 21/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3139 - accuracy: 0.1025 - val_loss: 2.3146 - val_accuracy: 0.1060\n",
      "Epoch 22/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3138 - accuracy: 0.1021 - val_loss: 2.3095 - val_accuracy: 0.1035\n",
      "Epoch 23/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3138 - accuracy: 0.1041 - val_loss: 2.3183 - val_accuracy: 0.1060\n",
      "Epoch 24/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3145 - accuracy: 0.1013 - val_loss: 2.3187 - val_accuracy: 0.0997\n",
      "Epoch 25/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3136 - accuracy: 0.1028 - val_loss: 2.3194 - val_accuracy: 0.1035\n",
      "Epoch 26/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3130 - accuracy: 0.1037 - val_loss: 2.3112 - val_accuracy: 0.1035\n",
      "Epoch 27/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3140 - accuracy: 0.1031 - val_loss: 2.3201 - val_accuracy: 0.1081\n",
      "Epoch 28/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3140 - accuracy: 0.1021 - val_loss: 2.3147 - val_accuracy: 0.1060\n",
      "Epoch 29/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3129 - accuracy: 0.1039 - val_loss: 2.3124 - val_accuracy: 0.0998\n",
      "Epoch 30/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3147 - accuracy: 0.1028 - val_loss: 2.3104 - val_accuracy: 0.0989\n",
      "Epoch 31/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3136 - accuracy: 0.1033 - val_loss: 2.3192 - val_accuracy: 0.1060\n",
      "Epoch 32/32\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3132 - accuracy: 0.1024 - val_loss: 2.3167 - val_accuracy: 0.1060\n",
      "Epoch 1/32\n",
      "1500/1500 [==============================] - 28s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 2/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 3/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 4/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 5/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 6/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 7/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 8/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 9/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 10/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 11/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 12/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 13/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 14/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 15/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 16/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 17/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 18/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 19/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 20/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 21/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 22/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 23/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 24/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 25/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 26/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 27/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 28/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 29/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 30/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 31/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
      "Epoch 32/32\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n"
     ]
    }
   ],
   "source": [
    "def build_model(hyperparams):\n",
    "    # Construct a model based on hyperparams\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hyperparams[\"layers\"][1], activation=hyperparams[\"activation\"]))\n",
    "\n",
    "    for _ in range(hyperparams[\"layers\"][0]):\n",
    "        model.add(keras.layers.Dense(hyperparams[\"layers\"][1], activation=hyperparams[\"activation\"]))\n",
    "\n",
    "    optimizer = keras.optimizers.legacy.Adam(learning_rate=hyperparams[\"learning_rate\"])\n",
    "\n",
    "    # Output layer for multi-class classification (10 classes) with softmax activation\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Example hyperparameters to tune\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "layer_configs = [(32, 32), (64, 64), (128, 128)]\n",
    "#learning_rates = [0.01]\n",
    "#layer_configs = [(32, 32)]\n",
    "models = []\n",
    "\n",
    "# Loop through different hyperparameters and train models\n",
    "for lr in learning_rates:\n",
    "    for layers in layer_configs:\n",
    "        # Build and train your model\n",
    "        hyperparams = {\"layers\": layers, \"activation\": \"relu\", \"learning_rate\": lr}\n",
    "        model = build_model(hyperparams)\n",
    "        model.fit(X_train, y_train, epochs=32, verbose=1, validation_split=0.2)\n",
    "        models.append((model, hyperparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy with {'layers': (32, 32), 'activation': 'relu', 'learning_rate': 0.001}:\t0.7922000288963318\n",
      "Model accuracy with {'layers': (64, 64), 'activation': 'relu', 'learning_rate': 0.001}:\t0.11349999904632568\n",
      "Model accuracy with {'layers': (128, 128), 'activation': 'relu', 'learning_rate': 0.001}:\t0.11349999904632568\n",
      "Model accuracy with {'layers': (32, 32), 'activation': 'relu', 'learning_rate': 0.01}:\t0.11349999904632568\n",
      "Model accuracy with {'layers': (64, 64), 'activation': 'relu', 'learning_rate': 0.01}:\t0.11349999904632568\n",
      "Model accuracy with {'layers': (128, 128), 'activation': 'relu', 'learning_rate': 0.01}:\t0.10090000182390213\n",
      "Model accuracy with {'layers': (32, 32), 'activation': 'relu', 'learning_rate': 0.1}:\t0.11349999904632568\n",
      "Model accuracy with {'layers': (64, 64), 'activation': 'relu', 'learning_rate': 0.1}:\t0.11349999904632568\n",
      "Model accuracy with {'layers': (128, 128), 'activation': 'relu', 'learning_rate': 0.1}:\t0.09799999743700027\n"
     ]
    }
   ],
   "source": [
    "def evaluate_models(models, X_test, y_test):\n",
    "    \n",
    "    # Evaluate each model\n",
    "    for model, hyperparams in models:\n",
    "        # Evaluate and print accuracy\n",
    "        loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f\"Model accuracy with {hyperparams}:\\t{accuracy}\")\n",
    "        \n",
    "evaluate_models(models, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588e2102-d8a6-459f-a9a5-b9d756090c83",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "Plot the accuracy and loss for different hyperparameter settings.\n",
    "\n",
    "## Analysis and Questions\n",
    "* How did different learning rates affect the training process and model accuracy?\n",
    "* What impact did varying the number of layers and neurons have on the model's performance?\n",
    "* Were there any combinations of hyperparameters that resulted in particularly good or poor performance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd49c263-b865-4aef-a4c0-10b337300430",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "## Part 2: Automated Hyperparameter Tuning\n",
    "### Objective\n",
    "Use automated methods like Grid Search and Random Search for hyperparameter tuning.\n",
    "\n",
    "### Setup\n",
    "Reuse the MNIST dataset setup from Part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f58055-b61f-4e4c-8358-fc6d8121874e",
   "metadata": {},
   "source": [
    "### Task: Automated Hyperparameter Tuning\n",
    "1. Grid Search and Random Search: Introduce and apply Grid Search and Random Search using scikit-learn's GridSearchCV or RandomizedSearchCV.\n",
    "2. Integration with Keras: Show how to use these methods with Keras models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fbe24fe-a682-4835-a788-06776264f1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 18 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n18 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py\", line 1491, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py\", line 760, in fit\n    self._fit(\n  File \"/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py\", line 926, in _fit\n    self._check_model_compatibility(y)\n  File \"/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py\", line 549, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\nTypeError: object of type 'NoneType' has no len()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/philipdecanesie/Library/CloudStorage/OneDrive-Personal/School-ITHS/Projects/Deep_Learning/Lec/Lec_05/Material/Hyperparameter_tuning.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/philipdecanesie/Library/CloudStorage/OneDrive-Personal/School-ITHS/Projects/Deep_Learning/Lec/Lec_05/Material/Hyperparameter_tuning.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodel_to_search, param_grid\u001b[39m=\u001b[39mparam_grid, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/philipdecanesie/Library/CloudStorage/OneDrive-Personal/School-ITHS/Projects/Deep_Learning/Lec/Lec_05/Material/Hyperparameter_tuning.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Run grid search\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/philipdecanesie/Library/CloudStorage/OneDrive-Personal/School-ITHS/Projects/Deep_Learning/Lec/Lec_05/Material/Hyperparameter_tuning.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m grid_result \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/philipdecanesie/Library/CloudStorage/OneDrive-Personal/School-ITHS/Projects/Deep_Learning/Lec/Lec_05/Material/Hyperparameter_tuning.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(classification_report(y_test, grid_result\u001b[39m.\u001b[39mpredict(X_test)))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[1;32m    877\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 18 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n18 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py\", line 1491, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py\", line 760, in fit\n    self._fit(\n  File \"/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py\", line 926, in _fit\n    self._check_model_compatibility(y)\n  File \"/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py\", line 549, in _check_model_compatibility\n    if self.n_outputs_expected_ != len(self.model_.outputs):\nTypeError: object of type 'NoneType' has no len()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define a function to create a model (for KerasClassifier)\n",
    "def create_model_to_search(optimizer=\"adam\", hidden_units=32, learning_rate=0.001):\n",
    "    # Create a Keras model with hyperparameters\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hidden_units, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model    \n",
    "\n",
    "# Set up GridSearchCV or RandomizedSearchCV\n",
    "model_to_search = KerasClassifier(build_fn=create_model_to_search, hidden_units=16)\n",
    "param_grid = {\n",
    "    # Define a grid of hyperparameters to search\n",
    "    \"hidden_units\": [16, 32, 64],\n",
    "    \"optimizer\": ['adam', 'sgd']\n",
    "}\n",
    "grid = GridSearchCV(estimator=model_to_search, param_grid=param_grid, verbose=1, cv=3)\n",
    "\n",
    "# Run grid search\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "print(classification_report(y_test, grid_result.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3550919-24ac-4001-a2a0-1e0bb583adbc",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "Visualize the performance of the best model found by the search methods.\n",
    "## Analysis and Questions\n",
    "* Compare the results of manual tuning with automated tuning. Which method gave better results?\n",
    "* What are the advantages and limitations of using automated methods like Grid Search and Random Search?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a73a6e8f-a9bc-4ed8-85d6-71ade7920ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "2023-11-30 11:35:46.797905: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-11-30 11:35:46.797943: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-11-30 11:35:46.797954: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-11-30 11:35:46.798013: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-30 11:35:46.798046: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "2023-11-30 11:35:46.940064: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-11-30 11:35:46.940084: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-11-30 11:35:46.940090: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-11-30 11:35:46.940120: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-30 11:35:46.940136: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "2023-11-30 11:35:47.115390: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-11-30 11:35:47.115411: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-11-30 11:35:47.115417: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-11-30 11:35:47.115448: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-30 11:35:47.115463: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "2023-11-30 11:35:47.170496: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-11-30 11:35:47.170524: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-11-30 11:35:47.170530: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-11-30 11:35:47.170691: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-30 11:35:47.170710: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "2023-11-30 11:35:47.450714: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-11-30 11:35:47.450742: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-11-30 11:35:47.450863: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-11-30 11:35:47.451834: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-30 11:35:47.451868: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-11-30 11:35:47.453694: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-11-30 11:35:47.453715: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-11-30 11:35:47.453853: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-11-30 11:35:47.453900: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-30 11:35:47.453928: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-11-30 11:35:47.455225: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-11-30 11:35:47.455242: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-11-30 11:35:47.456366: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-11-30 11:35:47.456792: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-30 11:35:47.456819: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "2023-11-30 11:35:47.471820: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-11-30 11:35:47.471876: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-11-30 11:35:47.473267: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-11-30 11:35:47.473410: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-30 11:35:47.473438: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-11-30 11:35:48.157044: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-30 11:35:48.272013: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-30 11:35:48.304445: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-30 11:35:48.413211: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-30 11:35:48.548887: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-30 11:35:48.589033: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-30 11:35:48.957896: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-11-30 11:35:48.975395: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/philipdecanesie/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/philipdecanesie/Library/CloudStorage/OneDrive-Personal/School-ITHS/Projects/Deep_Learning/Lec/Lec_05/Material/Hyperparameter_tuning.ipynb Cell 11\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/philipdecanesie/Library/CloudStorage/OneDrive-Personal/School-ITHS/Projects/Deep_Learning/Lec/Lec_05/Material/Hyperparameter_tuning.ipynb#X13sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# Perform GridSearchCV\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/philipdecanesie/Library/CloudStorage/OneDrive-Personal/School-ITHS/Projects/Deep_Learning/Lec/Lec_05/Material/Hyperparameter_tuning.ipynb#X13sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodel, param_grid\u001b[39m=\u001b[39mparam_grid, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/philipdecanesie/Library/CloudStorage/OneDrive-Personal/School-ITHS/Projects/Deep_Learning/Lec/Lec_05/Material/Hyperparameter_tuning.ipynb#X13sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m grid_result \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/philipdecanesie/Library/CloudStorage/OneDrive-Personal/School-ITHS/Projects/Deep_Learning/Lec/Lec_05/Material/Hyperparameter_tuning.ipynb#X13sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# Print the best results\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/philipdecanesie/Library/CloudStorage/OneDrive-Personal/School-ITHS/Projects/Deep_Learning/Lec/Lec_05/Material/Hyperparameter_tuning.ipynb#X13sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m using \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (grid_result\u001b[39m.\u001b[39mbest_score_, grid_result\u001b[39m.\u001b[39mbest_params_))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Deep_Learning-hkl5jVZo/lib/python3.10/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape(x_train.shape[0], -1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(x_test.shape[0], -1).astype('float32') / 255.0\n",
    "\n",
    "# One-hot encode the target labels\n",
    "num_classes = 10\n",
    "y_train = np.eye(num_classes)[y_train]\n",
    "y_test = np.eye(num_classes)[y_test]\n",
    "\n",
    "# Define the Keras model function\n",
    "def create_model(optimizer='adam', dropout_rate=0.2, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(784,), activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a KerasClassifier based on the model function\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Define the hyperparameters grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'batch_size': [64, 128],\n",
    "    'epochs': [10, 15],\n",
    "    'optimizer': ['adam', 'sgd'],\n",
    "    'model__dropout_rate': [0.2, 0.3],\n",
    "    'model__activation': ['relu', 'tanh']\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=1, n_jobs=-1)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# Print the best results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_result.best_estimator_\n",
    "test_loss, test_acc = best_model.model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
